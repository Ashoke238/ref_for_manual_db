name: Databricks CI Pipeline

on:
  push:
    branches: [dev]
  workflow_dispatch:

jobs:
  checkout-code:
    runs-on: ubuntu-latest
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v3

  static-code-analysis:
    runs-on: ubuntu-latest
    needs: checkout-code
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v3

      - name: üß™ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: üì¶ Install nbqa and flake8
        run: pip install nbqa flake8

      - name: üîç Run nbqa flake8 on notebooks
        run: |
          nbqa flake8 . || echo "Static analysis warnings only (non-blocking)"

  train-and-validate:
    runs-on: ubuntu-latest
    needs: static-code-analysis
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v3

      - name: üß™ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: üì¶ Install dependencies
        run: pip install requests mlflow

      - name: üöÄ Trigger Databricks Train Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          JOB_ID: 150430378558626
          RUN_ID_FILE: train_run_id.txt
        run: python trigger_job.py

      - name: üîÅ Export RUN_ID for train
        run: echo "RUN_ID=$(cat train_run_id.txt)" >> $GITHUB_ENV

      - name: ‚è≥ Wait for Databricks Train Job Completion
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: python wait_for_job.py

      - name: ‚úÖ Validate Training Metrics
        env:
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_REF_NAME: ${{ github.ref_name }}
          USER_EMAIL: ${{ secrets.MLFLOW_USER_EMAIL }}
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: python .github/scripts/validate_metrics.py

  trigger-inference-job:
    runs-on: ubuntu-latest
    needs: train-and-validate
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v3

      - name: üß™ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: üì¶ Install requests
        run: pip install requests

      - name: üöÄ Trigger Databricks Inference Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          JOB_ID: 643177853687692  # your inference job ID
          RUN_ID_FILE: inference_run_id.txt
        run: python trigger_job.py

      - name: üì§ Upload Inference RUN_ID
        uses: actions/upload-artifact@v3
        with:
          name: inference-run-id
          path: inference_run_id.txt

  wait-and-validate-inference:
    runs-on: ubuntu-latest
    needs: trigger-inference-job
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v3

      - name: üì¶ Download Inference RUN_ID
        uses: actions/download-artifact@v3
        with:
          name: inference-run-id

      - name: üß™ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: üì¶ Install dependencies
        run: pip install requests mlflow

      - name: üîÅ Export RUN_ID for inference
        run: echo "RUN_ID=$(cat inference_run_id.txt)" >> $GITHUB_ENV

      - name: ‚è≥ Wait for Inference Job Completion
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: python wait_for_job.py

      - name: ‚úÖ Validate Inference Metrics
        env:
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_REF_NAME: ${{ github.ref_name }}
          USER_EMAIL: ${{ secrets.MLFLOW_USER_EMAIL }}
        run: python .github/scripts/validate_inference_metrics.py
