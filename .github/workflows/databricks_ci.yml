name: Databricks CI Pipeline

on:
  push:
    branches: [dev]
  workflow_dispatch:

jobs:
  checkout-code:
    runs-on: ubuntu-latest
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v3

  static-code-analysis:
    runs-on: ubuntu-latest
    needs: checkout-code
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v3

      - name: üß™ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: üì¶ Install nbqa and flake8
        run: |
          pip install nbqa flake8

      - name: üîç Run nbqa flake8 on notebooks
        run: |
          nbqa flake8 . || echo "Static analysis warnings only (non-blocking)"

  trigger-databricks-job-dev:
    runs-on: ubuntu-latest
    needs: static-code-analysis
    steps:
      - name: üß™ Trigger Databricks Job (dev)
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          # Replace with your actual job ID
          JOB_ID=150430378558626

          RUN_ID=$(curl -s -X POST https://${DATABRICKS_HOST}/api/2.1/jobs/run-now \
            -H "Authorization: Bearer ${DATABRICKS_TOKEN}" \
            -H "Content-Type: application/json" \
            -d "{\"job_id\": $JOB_ID}" | jq -r '.run_id')

          echo "RUN_ID=$RUN_ID" >> $GITHUB_ENV
          echo "‚úÖ Triggered Databricks job with RUN_ID=$RUN_ID"

  validate-results:
    runs-on: ubuntu-latest
    needs: trigger-databricks-job-dev
    steps:
      - name: ‚è≥ Wait for Databricks Job Completion
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          MAX_RETRIES=20
          RETRY_DELAY=15

          for i in $(seq 1 $MAX_RETRIES); do
            STATUS=$(curl -s -X GET https://${DATABRICKS_HOST}/api/2.1/jobs/runs/get \
              -H "Authorization: Bearer ${DATABRICKS_TOKEN}" \
              --data-urlencode run_id=$RUN_ID | jq -r '.state.life_cycle_state')

            echo "Job status: $STATUS"

            if [[ "$STATUS" == "TERMINATED" ]]; then
              RESULT_STATE=$(curl -s -X GET https://${DATABRICKS_HOST}/api/2.1/jobs/runs/get \
                -H "Authorization: Bearer ${DATABRICKS_TOKEN}" \
                --data-urlencode run_id=$RUN_ID | jq -r '.state.result_state')

              echo "Result: $RESULT_STATE"

              if [[ "$RESULT_STATE" == "SUCCESS" ]]; then
                echo "‚úÖ Databricks job completed successfully"
                break
              else
                echo "‚ùå Job failed"
                exit 1
              fi
            fi

            echo "‚è≥ Waiting..."
            sleep $RETRY_DELAY
          done

      - name: üß™ Validate MLflow Metrics
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          pip install mlflow
          python .github/scripts/validate_metrics.py
